{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 1: Tokenization"
      ],
      "metadata": {
        "id": "m1Zfuw10krR3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WlkR_aZhxZo",
        "outputId": "334b297a-13eb-4633-d4a4-670d05e3b091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spacy 3.7.5\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "print(spacy.__name__, spacy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "jhpReSYjiDTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Noah doesn't like to run when it rains.\"\n",
        "\n",
        "doc = nlp(s)"
      ],
      "metadata": {
        "id": "mM0cEmHEiOae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([t.text for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQu0b48Pid-f",
        "outputId": "1770d729-39a7-42c2-a5a9-d26c7451a557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Noah', 'does', \"n't\", 'like', 'to', 'run', 'when', 'it', 'rains', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc[0])\n",
        "print(doc[0:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d49aVTepinFV",
        "outputId": "1c0a8f3a-ed7d-40bd-f31b-341eeb93e44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noah\n",
            "Noah doesn't\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(doc))\n",
        "print(type(doc[0]))\n",
        "print(type(doc[0:3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzlY5Cr9i0n8",
        "outputId": "22de1944-219b-4d1d-840b-8a89705889ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'spacy.tokens.doc.Doc'>\n",
            "<class 'spacy.tokens.token.Token'>\n",
            "<class 'spacy.tokens.span.Span'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc[3].text)\n",
        "print(doc[3].lang_)\n",
        "print(doc[3].__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iabPBAoVjGGg",
        "outputId": "46d6560e-a479-4a69-bde3-b5397461f881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "like\n",
            "en\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([[t.text, t.i] for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQbaXUaxjqR-",
        "outputId": "7f7b6e6a-2e16-4f9f-b760-17608991d190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Noah', 0], ['does', 1], [\"n't\", 2], ['like', 3], ['to', 4], ['run', 5], ['when', 6], ['it', 7], ['rains', 8], ['.', 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Hello! It's me Adam. We have met before.\"\n",
        "doc = nlp(s)\n",
        "sents = list(doc.sents)\n",
        "print(sents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMXVgUtgkHID",
        "outputId": "911e034b-cca5-408c-8865-d4c19b103e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Hello!, It's me Adam., We have met before.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson : Pre_Processing"
      ],
      "metadata": {
        "id": "zMI3wpqqkvVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "case folding"
      ],
      "metadata": {
        "id": "-M5FijVzmO4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"The train to London leaves at 10am on Tuseday\"\n",
        "doc = nlp(s)\n",
        "\n",
        "print(\"Before preprocessing with case folding:\")\n",
        "print([t.text for t in doc])\n",
        "\n",
        "print(\"After preprocessing with case folding:\")\n",
        "print([t.lower_ for t in doc])\n",
        "\n",
        "print(\"Case folding but skip the first word:\")\n",
        "print([t.lower_ if not t.is_sent_start else t.text for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quo1xotqkiVz",
        "outputId": "efb24a35-3252-4f46-9d92-1e43bd7d6676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before preprocessing with case folding:\n",
            "['The', 'train', 'to', 'London', 'leaves', 'at', '10', 'am', 'on', 'Tuseday']\n",
            "After preprocessing with case folding:\n",
            "['the', 'train', 'to', 'london', 'leaves', 'at', '10', 'am', 'on', 'tuseday']\n",
            "Case folding but skip the first word:\n",
            "['The', 'train', 'to', 'london', 'leaves', 'at', '10', 'am', 'on', 'tuseday']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "stop word removal"
      ],
      "metadata": {
        "id": "Xo3ajJBjmXuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All the stop word in EN:\")\n",
        "print(nlp.Defaults.stop_words)\n",
        "print(len(nlp.Defaults.stop_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhNJlP-ClPiQ",
        "outputId": "3dfd7b59-b6f6-4806-adfc-3346319a1adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the stop word in EN:\n",
            "{'here', 'much', 'all', '‘ll', 'at', 'indeed', 'latter', 'towards', 'yourself', 'thence', 'meanwhile', 'hereupon', 'go', 'have', 'part', 'against', 'six', 'used', 'or', 'might', 'see', 'not', 'mine', 'besides', 'none', 'between', \"'ll\", 'done', 'more', '‘ve', 'wherever', 'fifty', 'both', 'whereas', 'you', 'over', 'hers', 'her', 'moreover', 'nor', 'bottom', 'next', 'these', \"'re\", 'about', 'too', 'whereafter', 'whoever', 'as', 'what', 'top', 'together', 'whom', 'thereafter', 'also', \"'d\", 'sixty', 'whereby', \"'ve\", 'namely', 'forty', 'can', 'nine', 'could', 'how', 'everywhere', 'move', 'without', 'quite', \"n't\", 'ever', 'only', 'several', 'made', 'he', 'after', 'becoming', 'due', 'am', 'now', 'thru', 'whence', 'themselves', '’d', 'my', '‘d', 'regarding', 'been', 'no', 'become', 'yourselves', 'even', 'every', 'get', 'of', 'give', 'amount', 'will', 'his', 'often', 'serious', 'down', 'therein', 'really', 'among', 'full', 'myself', 'per', 'ourselves', 'very', 'everything', 'last', 'their', 'cannot', 'side', 'such', 'while', 'any', 'four', 'this', 'once', 'many', 'ten', 'a', 'rather', 'whereupon', 'until', 'first', '’s', 'most', 'nevertheless', 'above', 'either', 'nobody', '’re', 'noone', 'yet', 'must', 'do', 'in', 'already', 'seemed', 'before', 'twenty', 'just', 'those', 'same', 'off', 'therefore', 'unless', 'throughout', 'are', 'since', 'from', '’ll', 'alone', 'twelve', 'did', 'again', 'where', 'via', 'which', 'latterly', 'should', 'other', 'into', 'anywhere', 'each', 'elsewhere', 'five', 'be', 'almost', 'three', 'front', 'somewhere', 'formerly', 'least', 'and', 'using', 'had', 'thereupon', 'name', 'has', 'another', 'otherwise', 'when', 'below', 'up', 'whether', 'there', 'else', 'whose', 'someone', 'put', '’m', 'two', 'amongst', 'anyone', 'take', 'one', 'whole', 'herein', 'with', 'hence', 'seeming', 'because', 'however', 'than', 'out', 'thereby', 'may', 'if', 'during', 'himself', 'its', 'us', 'around', 'on', 'she', 'former', 'i', 'they', 'me', 'becomes', 'along', 'doing', 'please', 'him', 'but', 'toward', 'show', 'always', 'sometime', 'though', 'upon', '’ve', 'beyond', 'them', 'anyhow', 'perhaps', 'were', 'somehow', 'whatever', 'further', 'enough', 'hereby', 'although', 'an', 'your', 'say', 'across', '‘s', 'everyone', 'onto', 'third', 'behind', 'whither', 'mostly', \"'m\", 'various', 'it', '‘re', 'well', 'afterwards', 'eleven', 'own', 'seems', 'does', 'beforehand', 'who', 'being', 'eight', 'some', 'the', 'nowhere', 'wherein', 'is', 'except', 'seem', 'then', 'few', 'ours', 'to', 'hundred', 'something', 'n’t', 'was', 'within', 'keep', 'under', 'neither', 'our', 'we', 'so', 'call', \"'s\", 'beside', 'make', 'by', 'ca', 'n‘t', 'yours', 'why', 'thus', 'empty', 'hereafter', 'less', 'anyway', 'became', 'never', 'whenever', 'back', 'for', 'still', 'itself', '‘m', 'herself', 'that', 'through', 'would', 'anything', 'fifteen', 'nothing', 'others', 'sometimes', 're'}\n",
            "326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before using stop word removal:\")\n",
        "print([t.text for t in doc])\n",
        "\n",
        "print(\"After using stop word removal:\")\n",
        "print([t.text for t in doc if not t.is_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9oQHRSzm9ok",
        "outputId": "3534ff96-cd70-4502-85ba-d5033d4acffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before using stop word removal:\n",
            "['The', 'train', 'to', 'London', 'leaves', 'at', '10', 'am', 'on', 'Tuseday']\n",
            "After using stop word removal:\n",
            "['train', 'London', 'leaves', '10', 'Tuseday']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Customize stop word list:\")\n",
        "#nlp.Default.stop_words.add(\"ergo\")\n",
        "#nlp.Default.stop_words.remove(\"whatever\")"
      ],
      "metadata": {
        "id": "M1NnYkBRq4ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lemmatization"
      ],
      "metadata": {
        "id": "IJtDeA3DoJmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"She is the fastest swimmer.\"\n",
        "\n",
        "doc = nlp(s)"
      ],
      "metadata": {
        "id": "6BnZbtq_rlTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([(t.text,t.lemma_) for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXspq63tor3z",
        "outputId": "26acb2bb-c9a4-4577-fe57-bc71cb36e97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('She', 'she'), ('is', 'be'), ('the', 'the'), ('fastest', 'fast'), ('swimmer', 'swimmer'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "part of speech tagging"
      ],
      "metadata": {
        "id": "hU8HYQ2ZpDNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"I love pizza.\"\n",
        "\n",
        "doc = nlp(s)\n",
        "\n",
        "print([(t.text, t.pos_) for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0Tl62Heo17F",
        "outputId": "0c806c39-bcfb-45e1-d21e-c5e6903a91dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRON'), ('love', 'VERB'), ('pizza', 'NOUN'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([[t.pos_, spacy.explain(t.pos_)] for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHBr8cgspzBj",
        "outputId": "d279ae81-705c-4b47-c293-bb1058c03009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['PRON', 'pronoun'], ['VERB', 'verb'], ['NOUN', 'noun'], ['PUNCT', 'punctuation']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "2jqDw-n4qreF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
        "doc = nlp(s)"
      ],
      "metadata": {
        "id": "4TLRIpbmrm3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([[t.text, t.ent_type_] for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am99IVuvqXnG",
        "outputId": "bedb3d7d-d749-48ff-94d9-27e63db90492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Apple', 'ORG'], ['is', ''], ['looking', ''], ['at', ''], ['buying', ''], ['U.K.', 'GPE'], ['startup', ''], ['for', ''], ['$', 'MONEY'], ['1', 'MONEY'], ['billion', 'MONEY']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([[t.text, t.ent_type_] for t in doc if t.ent_type_ != 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMHTC6wLrje0",
        "outputId": "6c7f3d09-35da-4fd5-c767-05a5d78e5e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Apple', 'ORG'], ['is', ''], ['looking', ''], ['at', ''], ['buying', ''], ['U.K.', 'GPE'], ['startup', ''], ['for', ''], ['$', 'MONEY'], ['1', 'MONEY'], ['billion', 'MONEY']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('ORG:', spacy.explain('ORG'))\n",
        "print('GPE:', spacy.explain('GPE'))\n",
        "print('MONEY:', spacy.explain('MONEY'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdn8Yjy5sfrj",
        "outputId": "8ec0fac7-cd1a-4232-ceaa-45feaa069b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORG: Companies, agencies, institutions, etc.\n",
            "GPE: Countries, cities, states\n",
            "MONEY: Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([[t.text, t.label_] for t in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKYjBY3jti0F",
        "outputId": "46e3150c-03ab-4103-c83a-52923afcc432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Apple', 'ORG'], ['U.K.', 'GPE'], ['$1 billion', 'MONEY']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style = 'ent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "9UYL0O3Lt2Bu",
        "outputId": "b94e69f7-7661-4244-c125-28e535d61c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is looking at buying \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.K.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " startup for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $1 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 3: BOW and similarity"
      ],
      "metadata": {
        "id": "BXIYQk_MwUPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag_Of_Words (BOW)"
      ],
      "metadata": {
        "id": "qxLDKONDweqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOW using sklearn"
      ],
      "metadata": {
        "id": "R-NpeWV2xL2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "QMj9HEHEuqe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"Inflation surges around the world.\",\n",
        "    \"The Omicron coronavirus variant spreads.\",\n",
        "    \"World population exceeds 8 billion.\",\n",
        "    \"AI predicts protein structures.\"\n",
        "]"
      ],
      "metadata": {
        "id": "DjTe7oWCzBzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "bow = vectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "uaAu7XqQznbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkrDpcY13Qld",
        "outputId": "a580f6db-52fb-4501-ad04-574df6b1fae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inflation': 5,\n",
              " 'surges': 12,\n",
              " 'around': 1,\n",
              " 'the': 13,\n",
              " 'world': 15,\n",
              " 'omicron': 6,\n",
              " 'coronavirus': 3,\n",
              " 'variant': 14,\n",
              " 'spreads': 10,\n",
              " 'population': 7,\n",
              " 'exceeds': 4,\n",
              " 'billion': 2,\n",
              " 'ai': 0,\n",
              " 'predicts': 8,\n",
              " 'protein': 9,\n",
              " 'structures': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qly_ml043TQT",
        "outputId": "0b8aa5f4-54de-4661-a2de-bdce0dc64f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x16 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 18 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fiUcMfE3efX",
        "outputId": "647354a5-95b9-4356-e0d6-a4d99193fcdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 5)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 1)\t1\n",
            "  (0, 13)\t1\n",
            "  (0, 15)\t1\n",
            "  (1, 13)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 10)\t1\n",
            "  (2, 15)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 4)\t1\n",
            "  (2, 2)\t1\n",
            "  (3, 0)\t1\n",
            "  (3, 8)\t1\n",
            "  (3, 9)\t1\n",
            "  (3, 11)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opDCTtqF30P8",
        "outputId": "5ee7fb62-6e30-4824-9180-5a5616de4f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
              "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "custom tokenizer with spacy"
      ],
      "metadata": {
        "id": "HXaibr7L5Pfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_tokenizer(doc):\n",
        "  return [t.lemma_ for t in nlp(doc) if (not t.is_stop) and (not t.is_punct)]"
      ],
      "metadata": {
        "id": "OUmhkCcz4Sk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(tokenizer = custom_tokenizer, binary = True)\n",
        "\n",
        "bow = vectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSrOokwP9hsd",
        "outputId": "01f747b0-8182-4225-ca38-6ad5f16a6f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HVmqnXI-Jou",
        "outputId": "501878ee-b198-45cb-d992-5a4a187c3478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inflation': 5,\n",
              " 'surge': 12,\n",
              " 'world': 14,\n",
              " 'omicron': 6,\n",
              " 'coronavirus': 3,\n",
              " 'variant': 13,\n",
              " 'spread': 10,\n",
              " 'population': 7,\n",
              " 'exceed': 4,\n",
              " '8': 0,\n",
              " 'billion': 2,\n",
              " 'ai': 1,\n",
              " 'predict': 8,\n",
              " 'protein': 9,\n",
              " 'structure': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow[:, 0:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z47Zyo28-SSp",
        "outputId": "6c9569fa-0839-4fc6-c4c3-f388ead2be24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (1, 3)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 2)\t1\n",
            "  (3, 1)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "document similarity"
      ],
      "metadata": {
        "id": "YPMSQwko4n2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(a,b):\n",
        "  return np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n"
      ],
      "metadata": {
        "id": "MLjIsd13FIV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus[1])\n",
        "print(bow[1])\n",
        "print(\"=> \", bow[1].toarray().squeeze())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlhYrwgO49oX",
        "outputId": "caeb6b59-9203-4a81-9c6a-ea2c626224cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Omicron coronavirus variant spreads.\n",
            "  (0, 6)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 13)\t1\n",
            "  (0, 10)\t1\n",
            "=>  [0 0 0 1 0 0 1 0 0 0 1 0 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus[1])\n",
        "print(corpus[3])\n",
        "print(f'Similarity score: {cosine_sim(bow[1].toarray().squeeze(),bow[3].toarray().squeeze()):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksCQ292t5t9t",
        "outputId": "e57cd8e2-1b92-4726-af0f-a4be055e1b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Omicron coronavirus variant spreads.\n",
            "AI predicts protein structures.\n",
            "Similarity score: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus[0])\n",
        "print(corpus[2])\n",
        "print(f'Similarity score: {cosine_sim(bow[0].toarray().squeeze(),bow[2].toarray().squeeze()):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWvYtEoj6QX7",
        "outputId": "e51f8b6b-6406-4d33-9d05-b701fdc7a276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inflation surges around the world.\n",
            "World population exceeds 8 billion.\n",
            "Similarity score: 0.258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(bow))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyYdSsef6ZRr",
        "outputId": "4a83c220-120c-4f92-9697-8eb10c00c910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.         0.25819889 0.        ]\n",
            " [0.         1.         0.         0.        ]\n",
            " [0.25819889 0.         1.         0.        ]\n",
            " [0.         0.         0.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n-grams"
      ],
      "metadata": {
        "id": "qP64f90M7TH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(tokenizer = custom_tokenizer, lowercase = False, binary = True, ngram_range = (1,2))\n",
        "\n",
        "unibigrams = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(f'Size of vocabulary: {len(vectorizer.get_feature_names_out())}')\n",
        "\n",
        "print(vectorizer.vocabulary_)\n",
        "\n",
        "for i in vectorizer.vocabulary_:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TG99cIn68gs",
        "outputId": "dabb6bbd-a849-4d4d-e53e-5427f90e1476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 27\n",
            "{'inflation': 11, 'surge': 21, 'world': 25, 'inflation surge': 12, 'surge world': 22, 'Omicron': 4, 'coronavirus': 7, 'variant': 23, 'spread': 19, 'Omicron coronavirus': 5, 'coronavirus variant': 8, 'variant spread': 24, 'population': 13, 'exceed': 9, '8': 0, 'billion': 6, 'world population': 26, 'population exceed': 14, 'exceed 8': 10, '8 billion': 1, 'AI': 2, 'predict': 15, 'protein': 17, 'structure': 20, 'AI predict': 3, 'predict protein': 16, 'protein structure': 18}\n",
            "inflation\n",
            "surge\n",
            "world\n",
            "inflation surge\n",
            "surge world\n",
            "Omicron\n",
            "coronavirus\n",
            "variant\n",
            "spread\n",
            "Omicron coronavirus\n",
            "coronavirus variant\n",
            "variant spread\n",
            "population\n",
            "exceed\n",
            "8\n",
            "billion\n",
            "world population\n",
            "population exceed\n",
            "exceed 8\n",
            "8 billion\n",
            "AI\n",
            "predict\n",
            "protein\n",
            "structure\n",
            "AI predict\n",
            "predict protein\n",
            "protein structure\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF_IDF"
      ],
      "metadata": {
        "id": "qyBcRTuaOEx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF with sklearn"
      ],
      "metadata": {
        "id": "H6PpUDeiOIOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "an4mKqpo8rDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = fetch_20newsgroups(categories = ['sci.space'], remove = ('headers','footers','quotes'))\n",
        "\n",
        "print(len(corpus.data))\n",
        "print(corpus.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvWE6NgDKB5z",
        "outputId": "4acf508c-ec4a-40df-f103-1cd20a7d88c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "593\n",
            "\n",
            "Any lunar satellite needs fuel to do regular orbit corrections, and when\n",
            "its fuel runs out it will crash within months.  The orbits of the Apollo\n",
            "motherships changed noticeably during lunar missions lasting only a few\n",
            "days.  It is *possible* that there are stable orbits here and there --\n",
            "the Moon's gravitational field is poorly mapped -- but we know of none.\n",
            "\n",
            "Perturbations from Sun and Earth are relatively minor issues at low\n",
            "altitudes.  The big problem is that the Moon's own gravitational field\n",
            "is quite lumpy due to the irregular distribution of mass within the Moon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pre_processing\n",
        "apply lemmatization, remove punctuation, spaces and non-alphabetic characters."
      ],
      "metadata": {
        "id": "_XyyaOnXMrS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "unwanted_pipes = [\"ner\", 'parser']\n",
        "\n",
        "def custom_tokenizer(doc):\n",
        "  with nlp.disable_pipes(*unwanted_pipes):\n",
        "    return [t.lemma_ for t in nlp(doc) if not t.is_punct and not t.is_space and t.is_alpha]"
      ],
      "metadata": {
        "id": "_IdcuAWKKzIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(tokenizer = custom_tokenizer)\n",
        "\n",
        "features = vectorizer.fit_transform(corpus.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKiO1FUfMEjD",
        "outputId": "aeea8646-b207-455b-c3f2-c8b397fe4911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtqVWqALzJXv",
        "outputId": "4a635e0e-7d62-4300-c6c6-f1e64c596ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 56690 stored elements and shape (593, 9463)>\n",
            "  Coords\tValues\n",
            "  (0, 424)\t0.07006735123597327\n",
            "  (0, 4943)\t0.17755697785104502\n",
            "  (0, 7310)\t0.08827255510573831\n",
            "  (0, 5573)\t0.07462737620371114\n",
            "  (0, 3317)\t0.1987888389166129\n",
            "  (0, 8517)\t0.06551158102003457\n",
            "  (0, 2378)\t0.04343054547334542\n",
            "  (0, 6912)\t0.13559878838138195\n",
            "  (0, 5908)\t0.21554277358564625\n",
            "  (0, 1847)\t0.13559878838138195\n",
            "  (0, 370)\t0.1054358136369086\n",
            "  (0, 9237)\t0.0715855496878138\n",
            "  (0, 4402)\t0.07522156165875085\n",
            "  (0, 7244)\t0.0978911139378133\n",
            "  (0, 5963)\t0.0643662961391887\n",
            "  (0, 4393)\t0.07654434326236456\n",
            "  (0, 9274)\t0.059872496633831214\n",
            "  (0, 1902)\t0.13559878838138195\n",
            "  (0, 9311)\t0.1929427392927135\n",
            "  (0, 5402)\t0.10099174099290609\n",
            "  (0, 8393)\t0.20401777246040834\n",
            "  (0, 5817)\t0.09912761029075574\n",
            "  (0, 449)\t0.10452131953855516\n",
            "  (0, 5429)\t0.17101697764367227\n",
            "  (0, 1348)\t0.09035933266335426\n",
            "  :\t:\n",
            "  (592, 5577)\t0.0608786291592942\n",
            "  (592, 3709)\t0.05774845667440134\n",
            "  (592, 1214)\t0.06529035949121127\n",
            "  (592, 7605)\t0.048924996010567184\n",
            "  (592, 8990)\t0.06529035949121127\n",
            "  (592, 606)\t0.06286240908557002\n",
            "  (592, 3046)\t0.06842053197610413\n",
            "  (592, 8331)\t0.05428346805566916\n",
            "  (592, 894)\t0.06842053197610413\n",
            "  (592, 4760)\t0.0608786291592942\n",
            "  (592, 1630)\t0.06529035949121127\n",
            "  (592, 722)\t0.05774845667440134\n",
            "  (592, 892)\t0.06842053197610413\n",
            "  (592, 1718)\t0.13684106395220827\n",
            "  (592, 691)\t0.06529035949121127\n",
            "  (592, 1355)\t0.16596151880628024\n",
            "  (592, 209)\t0.06842053197610413\n",
            "  (592, 2819)\t0.13684106395220827\n",
            "  (592, 4754)\t0.0728322623080212\n",
            "  (592, 372)\t0.0728322623080212\n",
            "  (592, 9417)\t0.0728322623080212\n",
            "  (592, 4840)\t0.0728322623080212\n",
            "  (592, 489)\t0.0728322623080212\n",
            "  (592, 3322)\t0.0728322623080212\n",
            "  (592, 1859)\t0.0728322623080212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Search"
      ],
      "metadata": {
        "id": "iQRyny2WOPrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = [\"Mars\"]\n",
        "\n",
        "query_tfidf = vectorizer.transform(query)\n",
        "\n",
        "print(query_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FePv1olTN4Jz",
        "outputId": "710a47d7-e20a-4afe-c4e5-d4c8fa31b66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 5026)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()"
      ],
      "metadata": {
        "id": "bho36fZ_O1tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k(arr, k):\n",
        "  kth_largest = (k+1)*-1\n",
        "  return np.argsort(arr)[:kth_largest:-1]\n",
        "\n",
        "top_related_indices = top_k(cosine_similarities, 5)\n",
        "print(top_related_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZtrwzX-PaI8",
        "outputId": "276c720e-fd71-402b-a658-8584caefeea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[468 583 410  79 343]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarities[top_related_indices])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6BXWKqOQQOH",
        "outputId": "216b1328-4e47-4abf-b15b-fece0d94361b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.32658502 0.1810773  0.15383114 0.14742523 0.14398152]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.data[top_related_indices[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so5nmWp3QcM6",
        "outputId": "097a3267-91a1-4d2c-972e-3cdb08ac9e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the deal with life on Mars?  I save the \"face\" and heard \n",
            "associated theories. (which sound thin to me)\n",
            "\n",
            "Are we going back to Mars to look at this face agian?\n",
            "Does anyone buy all the life theories?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.data[top_related_indices[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq6TBjoGQgZf",
        "outputId": "73fa2784-e65b-42fd-e692-263a53106874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A practical suggestion, to be sure, but one could *also* peek into\n",
            "news.lists, where Brian Reid has posted \"USENET Readership report for\n",
            "Mar 93.\" Another posting called \"USENET READERSHIP SUMMARY REPORT FOR\n",
            "MAR 93\" gives the methodology and caveats of Reid's survey.  (These\n",
            "postings failed to appear for a while-- I wonder why?-- but they are\n",
            "now back.)\n",
            "\n",
            "Reid, alas, gives us no measure of the \"power/influence\" of readers...\n",
            "Sorry, Mark.\n",
            "\n",
            "I suspect Mark, dangling out there on Fidonet, may not get news.lists\n",
            "so I've mailed him copies of these reports.\n",
            "\n",
            "The bottom line?\n",
            "\n",
            "        +-- Estimated total number of people who read the group, worldwide.\n",
            "        |     +-- Actual number of readers in sampled population\n",
            "        |     |     +-- Propagation: how many sites receive this group at all\n",
            "        |     |     |      +-- Recent traffic (messages per month)\n",
            "        |     |     |      |      +-- Recent traffic (kilobytes per month)\n",
            "        |     |     |      |      |      +-- Crossposting percentage\n",
            "        |     |     |      |      |      |    +-- Cost ratio: $US/month/rdr\n",
            "        |     |     |      |      |      |    |      +-- Share: % of newsrders\n",
            "        |     |     |      |      |      |    |      |   who read this group.\n",
            "        V     V     V      V      V      V    V      V\n",
            "  88  62000  1493   80%  1958  4283.9    19%  0.10   2.9%  sci.space \n",
            "\n",
            "The first figure indicates that sci.space ranks 88th among most-read\n",
            "newsgroups.\n",
            "\n",
            "I've been keeping track sporadically to watch the growth of traffic\n",
            "and readership.  You might be entertained to see this.\n",
            "\n",
            "Oct 91   55  71000  1387   84%   718  1865.2    21%  0.04   4.2%  sci.space\n",
            "Mar 92   43  85000  1741   82%  1207  2727.2    13%  0.06   4.1%  sci.space\n",
            "Jul 92   48  94000  1550   80%  1044  2448.3    12%  0.04   3.8%  sci.space\n",
            "May 92   45  94000  2023   82%   834  1744.8    13%  0.04   4.1%  sci.space\n",
            "(some kind of glitch in estimating number of readers happens here)\n",
            "Sep 92   45  51000  1690   80%  1420  3541.2    16%  0.11   3.6%  sci.space \n",
            "Nov 92   78  47000  1372   81%  1220  2633.2    17%  0.08   2.8%  sci.space \n",
            "(revision in ranking groups happens here(?))\n",
            "Mar 93   88  62000  1493   80%  1958  4283.9    19%  0.10   2.9%  sci.space \n",
            "\n",
            "Possibly old Usenet hands could give me some more background on how to\n",
            "interpret these figures, glitches, or the history of Reid's reporting\n",
            "effort.  Take it to e-mail-- it doesn't belong in sci.space.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1,2,3,4,5,6]\n",
        "b = a[:-7:-1]\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE5kn0zAQjgU",
        "outputId": "2898e48c-82e6-486d-d39e-f2434825dba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 5, 4, 3, 2, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPV3HwuedfP6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}